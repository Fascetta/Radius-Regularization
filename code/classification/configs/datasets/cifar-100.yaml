dataset: CIFAR-100

# General training hyperparameters
num_epochs: 200
batch_size: 128
lr: 1e-1
weight_decay: 5e-4
use_lr_scheduler: True
lr_scheduler: MultiStepLR             # CosineAnnealingLR or MultiStepLR
lr_scheduler_milestones: [60, 120, 160]
lr_scheduler_gamma: 0.2
base_loss: cross_entropy               # cross_entropy or focal_loss
batch_size_test: 128
validation_split: False

# General validation/testing hyperparameters
batch_size_test: 128
validation_split: False